{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Data Partitioning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYC4OJQOiHeI",
        "outputId": "bec60095-e5f1-44aa-8531-1e34acdd899c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "import pandas as pd"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHQePfPiVWw"
      },
      "source": [
        "text=nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
        "tokenized_sents=nltk.sent_tokenize(text)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQfCj-DMxsU2"
      },
      "source": [
        "#global dataFrameT\n",
        "dataFrameT = pd.DataFrame()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YnnDRJ5iq6I"
      },
      "source": [
        "\n",
        "def listToString(s): \n",
        "  str1 = \"\"   \n",
        "  for ele in s: \n",
        "   str1 +=' '\n",
        "   str1 += ele  \n",
        "  return str1\n",
        "def stringOrList(x):\n",
        "  if type(x)==str:\n",
        "   textDataPartitioning(x)\n",
        "  elif type(x)==list:\n",
        "    for i in range(len(x)):\n",
        "      textDataPartitioning(x[i])\n",
        "\n",
        "def textDataPartitioning(x): \n",
        " example_sent=nltk.corpus.gutenberg.raw(x)\n",
        " stop_words = set(stopwords.words('english')) \n",
        " word_tokens = word_tokenize(example_sent)\n",
        " filtered_sentence = [] \n",
        " for w in word_tokens: \n",
        "     if w not in stop_words: \n",
        "         filtered_sentence.append(w) \n",
        " temp=[]\n",
        " list_of_lists = []\n",
        " list_of_lists1 = []\n",
        " index=0\n",
        " for word in filtered_sentence:\n",
        "   temp.append(word)\n",
        "   if len(temp)==100:\n",
        "    list_of_lists.append(temp)\n",
        "    temp=[]\n",
        " lenght=0\n",
        " for i in range(200):\n",
        "  ran=random.randint(0, len(list_of_lists)-1)\n",
        "  list_of_lists1.append([list_of_lists[ran], x])\n",
        " dataFrame = pd.DataFrame(list_of_lists1, columns=[\"partition\", \"book\"])\n",
        " global dataFrameT  \n",
        " dataFrameT=dataFrameT.append(dataFrame)\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM_XwJzVlPph",
        "outputId": "2cfb2e27-29b3-4de1-c748-c7ceafc4278b"
      },
      "source": [
        "#list of 100 words in first column\n",
        "oo=['chesterton-thursday.txt','austen-emma.txt']\n",
        "stringOrList(oo)\n",
        "print(dataFrameT)\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             partition                     book\n",
            "0    [held, bridge, ., But, worse, ,, first, appeal...  chesterton-thursday.txt\n",
            "1    [anarchist, ., But, gentleman, puts, top, hat,...  chesterton-thursday.txt\n",
            "2    [chief, I, spoken, ., You, really, come, see, ...  chesterton-thursday.txt\n",
            "3    [,, pale, yellow, flower, button-hole, ,, ,, s...  chesterton-thursday.txt\n",
            "4    [devils, laughing, sneezing, blowing, devilish...  chesterton-thursday.txt\n",
            "..                                                 ...                      ...\n",
            "195  [``, though, I, kept, thoughts, ;, I, perceive...          austen-emma.txt\n",
            "196  [eagerness, --, '', Never, ,, twentieth, part,...          austen-emma.txt\n",
            "197  [I, could, go, away, know, ,, rain, ;, I, wish...          austen-emma.txt\n",
            "198  [talk, first, letter, Enscombe, ``, Mr., Elton...          austen-emma.txt\n",
            "199  [;, mind, true, gentility, Harriet, Smith, cou...          austen-emma.txt\n",
            "\n",
            "[800 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}